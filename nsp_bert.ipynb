{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92db3080",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForNextSentencePrediction\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9506afe2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForNextSentencePrediction: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForNextSentencePrediction.from_pretrained('bert-base-uncased')\n",
    "\n",
    "text = (\"Head's thirst for big scores has increased in the last 14 months and is part of the reason for his return Test cricket.\")\n",
    "text2 = (\"In his last six first-class centuries since October 2020, including this hundred, he has converted five into 150-plus scores, after having only converted two of his first 12.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bd3b916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(text, text2, return_tensors='pt')\n",
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a94b4e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2132,  1005,  1055, 21810,  2005,  2502,  7644,  2038,  3445,\n",
       "          1999,  1996,  2197,  2403,  2706,  1998,  2003,  2112,  1997,  1996,\n",
       "          3114,  2005,  2010,  2709,  3231,  4533,  1012,   102,  1999,  2010,\n",
       "          2197,  2416,  2034,  1011,  2465,  4693,  2144,  2255, 12609,  1010,\n",
       "          2164,  2023,  3634,  1010,  2002,  2038,  4991,  2274,  2046,  5018,\n",
       "          1011,  4606,  7644,  1010,  2044,  2383,  2069,  4991,  2048,  1997,\n",
       "          2010,  2034,  2260,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5370b766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = torch.LongTensor([0])\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e79c6a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['loss', 'logits'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model(**inputs, labels=labels)\n",
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70cc884e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.4107e-06, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96c4bc23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.410734163684538e-06"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9e2748c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['logits'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model(**inputs)\n",
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7349db3",
   "metadata": {},
   "source": [
    "0 — meaning BERT believes sentence B **does** follow sentence A (correct)\n",
    "1 — meaning BERT believes sentence B **does not** follow sentence A (correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5ff6a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(outputs.logits)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anuj_research",
   "language": "python",
   "name": "anuj_research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
